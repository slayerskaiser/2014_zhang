\documentclass[../zhang_thesis.tex]{subfiles}
\begin{document}

\chapter{Introduction}

Batteries, particularly rechargeable ones, are used extensively in daily life. They provide the energy for such electrical systems as communication, automotive, and renewable power systems. In order to design for and operate these systems, an accurate battery model and a means of simulating the model efficiently are needed. For example, modern battery charge and health management schemes use high-fidelity battery models to track the state of charge (SOC) and state of health (SOH); this
information is then used to predict and optimize the runtime of the battery. However, widely-used chemical batteries have nonlinear capacitive effects, which require the use of a nonlinear filter for accurate prediction of their states in the presence of noise. This thesis explores one possible solution to this problem by choosing an appropriate battery model and testing the accuracy and speed of various nonlinear filters in determining the SOC through simulation. Note that only filters
using point-based numerical approximation methods were studied, as opposed to those using density-based methods. See~\cite{chen03} for more information about the differences between various numerical approximation methods in relationship to Bayesian filtering.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Electrical Characteristics of Rechargeable Batteries}
\label{sec:echar}

A high-fidelity battery model has to accurately reproduce the various characteristics of a battery. Most models keep track of the total capacity and SOC in order to predict remaining runtime. More accurate models include nonlinear effects, such as the rate-capacity effect and the recovery effect, along with self-discharge and the effects of ambient temperature. The dynamic electrical attributes, such as the current-voltage (i-v) characteristics and transient responses, can also be
modeled. The remainder of this section defines these characteristics.

The capacity of a battery is the amount of electric charge it can store, measured in the SI unit Ampere-hours (Ah). Commonly, for rechargeable battery specifications, the subunit milliampere-hour (mAh) is used instead. Related is the available capacity, which is the amount of charge that the battery can currently deliver. Due to the electrochemical nature of batteries, a battery's available capacity decreases as the rate of discharge increases, which is known as the rate-capacity effect. Therefore, the capacity for a
battery is typically stated for a given discharge rate.  Related to this is the recovery effect, so called because when a battery is allowed to rest during an idle period, the battery ``recovers'' available capacity previously lost during discharge because of the rate-capacity effect. Thus, a battery that is discharged at a high rate until its available capacity reaches zero, when allowed to rest, regains a portion of its lost capacity.

Both the rate-capacity effect and the recovery effect can be explained by the electrochemical nature of the battery. During discharge, the concentration of the active material around the electrode is depleted, and the active materials in the depletion region move towards the electrode to reduce the concentration gradient~\cite{chiasserini99}. Because the speed at which the concentration gradient is equalized is limited, the faster the rate of discharge, the less the active material is
replenished, resulting in a decrease in the available capacity. Likewise, when the battery is allowed to rest, the active material gradient has additional time to equalize, and the available capacity is increased.

Closely related to the capacity is the SOC. This thesis defines it as the ratio between the remaining capacity and the maximum capacity, with both capacities measured using the total amount of active material within the battery. Thus, this definition denotes the proportion of remaining chemical energy rather than the available chemical energy and is unaffected by the rate-capacity and recovery effects. Note that a fully charged battery has an SOC of unity and a fully discharged battery has an SOC of zero, regardless
of the available capacity. Additionally, there exists a nonlinear relationship between the SOC of the battery and its open-circuit voltage $V_{OC}$, which is useful for simulation of the i-v characteristics and transient responses. The $V_\text{OC}$ is the limit of the measured battery voltage after recovery, assuming no self-discharge.

Other, more minor effects that are commonly modeled are self-discharge, the effect of ambient temperature, and aging. Self-discharge refers to the decrease of an idle battery's SOC over time due to internal chemical reactions. It is dependent on the type of battery, SOC, ambient temperatures, and other factors. The ambient temperature has effects on the internal resistance of the battery and the self-discharge rate. Commonly, the battery is designed to operate within a narrow range of
temperatures. Below the operating temperature range, the internal resistance increases, decreasing the capacity. Above the operating range, the internal resistance decreases, not only increasing the capacity but also the self-discharge rate; thus, the deliverable capacity is lowered due to the increased self-discharge. Aging refers to the decrease in battery performance measures, such as capacity, self-discharge, and internal resistance, over time due to unwanted chemical reactions. In
practice, aging is indicated by the SOH, defined as the ratio between the current maximum capacity and that of a new battery. The SOH threshold at which the battery performance is considered too degraded varies by application.

This thesis is mainly concerned with estimating the SOC from noisy measurements. The SOH is easier to estimate as it changes slowly over charge cycles, rather than within each charge cycle. Additionally, no simplified expressions exist for the SOH, so it is usually determined empirically. Thus, only the estimation of the SOC was studied by this paper.

%This thesis studied the prediction of the SOC of a battery using noisy measurements of its current and voltage. To do so accurately for a general load, incorporation of the rate-capacity and recovery effects as well as the transient i-v characteristics is desirable. Furthermore, it is useful to have a model easily tunable for different battery types. The following section reviews the characteristics of different battery models and chooses the one most suitable for the purposes of this study.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Battery Models}

This thesis studied the estimation of the SOC of a battery given knowledge of the resistive load on the battery as well as noisy measurements of the voltage across its terminals. A known resistive load profile, rather than the current, was used because in a real-life usage, it is difficult to exactly control the current drawn by a load. In order to estimate the SOC for a general load profile, incorporation of the rate-capacity and recovery effects as well as the transient i-v characteristics
is desirable. Furthermore it is useful to have a model easily tunable for different battery types. To find a battery model that meets these goals, the major types of battery models are reviewed and their characteristics are compared.
%This section reviews the characteristics of major types of battery models.
Jongerden and Haverkort determined four main categories for battery models, namely electrochemical, analytical, stochastic, and electrical-circuit~\cite{jongerden08}.
Additionally, battery models that use computational intelligence exist, e.g.~\cite{man12,ogorman98,capizzi11,wang06,shen02}.
%Battery models can be divided into five categories, namely electrochemical, computational intelligence, analytical, stochastic, and electrical-circuit.
The remainder of this section reviews these five types and determines the most suitable battery model for this study.

\subsection{Electrochemical}

Electrochemical models describe the chemical processes that take place in the battery in great detail. These are generally the most accurate, but they require in-depth knowledge of the chemical processes to create and impose large computational costs~\cite{jongerden09}. One of the most widely known electrochemical models was developed by Doyle, Fuller, and Newman for lithium and lithium-ion batteries using noninvasive voltage-current cycling
experiments~\cite{doyle93,fuller94,fuller94b}. It consists of six coupled, nonlinear differential equations that capture lithium diffusion dynamics and charge transfer kinetics. The model is able to predict i-v response and provides a design guide for thermodynamics, kinetics, and transport across electrodes. A implementation of their model in Fortran, called Dualfoil, is available for free online.\footfullcite{newman98} The program needs more than 60 parameters along with the load profile
in order to compute the battery properties. Setting the parameters requires detailed knowledge of the battery, but as a result, the program is highly accurate. It is so accurate that other battery models are often compared to it rather than to experimental results.

\subsection{Computational Intelligence}

Computational intelligence is a branch of computer science interested in problems that require the intelligence of humans and animals to solve. One of the earliest definitions by Bezdek states that computational intelligent systems use pattern recognition on low-level, numerical data and do not use knowledge as with artificial intelligence~\cite{bezdek92,bezdek94}. Methods such as neural networks, fuzzy systems, and evolutionary computation are commonly classified as computational
intelligence. Battery models using such methods as neural networks~\cite{ogorman98,capizzi11}, support vector machines~\cite{wang06}, and hybrid neural-fuzzy models~\cite{shen02} have been studied. These models learn the nonlinear relationships between battery properties, such as SOC, current, voltage, and temperature, through a computationally costly training process. However, once trained, they incur a much lower cost and can achieve comparable accuracy to electrochemical
models.

\subsection{Analytical}

Analytical models are simplified electrochemical models that trade off accuracy for simplicity. One of the simplest such models is Peukert's law for lead-acid batteries, which states that for a one-ampere discharge rate~\cite{doerffel06}
\begin{equation}
C_p = I^k t,
\end{equation}
where $C_p$ is the capacity at a one-ampere discharge rate in Ah, $I$ is the discharge current in A, $t$ is the time to discharge the battery in hours, and $k\ge 1$ is the dimensionless Peukert constant, typically between $1.1$ and $1.3$ for a lead-acid battery. The constant $k$ only equals unity for an ideal accumulator, so for real batteries, $k$ is always greater than unity. Thus, for a given increase in the discharge current, the discharge time decreases by a proportionally greater
amount. Therefore, the effective, or available, capacity $C\times t$ is reduced. Peukert's law can be extended to some other battery chemistries, such as lithium-ion~\cite{doerffel06}. Note that Peukert's law models only the rate-capacity effect and not the recovery effect. More complicated models, such as the kinetic battery model and the diffusion model, are able to describe both effects.

The kinetic battery model (KiBaM), initially created for large lead-acid batteries, describes the battery as a kinetic process, using two charge wells for the bound and available charges connected by a valve whose flow rate is proportional to the height difference between the wells~\cite{manwell93}. The change of charge in the wells is given by
\begin{equation}
    \begin{cases}
        \dfrac{dy_1}{dt} = -I + k \left( h_2 - h_1 \right) \\
        \dfrac{dy_2}{dt} = -k \left( h_2 - h_1 \right),
    \end{cases}
    \label{eq:kibam}
\end{equation}
where $y_1,y_2$ are the charges, $h_1,h_2$ are the heights of the wells, the parameter $k$ controls the rate of charge flow between the wells, and $I$ is the applied load. The flow rate of the valve should be lower than the typical discharge rate of the battery. During discharge from the available-charge well, the bound charges flow through the valve to equalize the heights of the two wells. It can be seen that for slower discharge rates, more charge flows through the valve and the effective
capacity increases. Likewise, during idle periods, the battery recovers available charge.

Related to the KiBaM is the diffusion model, which describes the movement of the ions in the electrolyte of a lithium-ion battery~\cite{rakhmatov01}. Like in the kinetic battery model, the difference in the concentration of adjacent ions along the length of the battery determines the diffusion rate of the ions. The available charges are those ions directly touching the electrode of the battery. It can be seen that the KiBaM is a first-order approximation of the diffusion
model~\cite{jongerden09}, since the individual ions in the diffusion model are replaced by two charge wells in the KiBaM.

\subsection{Stochastic}

Stochastic models describe the discharging and the recovery effect as stochastic processes. The first models were developed by Chiasserini and Rao and based on discrete-time Markov chains~\cite{chiasserini99b}. They studied two models of a battery in a communication device that transmitted packets. The simpler model described the battery as a discrete-time Markov chain with $N+1$ states, numbered from $0$ to $N$ and corresponding to the number of charge units available in the battery.
Transmitting one packet requires one charge unit of energy. Thus, in continuous transmission, $N$ packets can be sent. At every time step, a charge unit is either consumed with probability $a_1=q$ or recovered with probability $a_0=1-q$. The battery is considered empty when the $0$ state is reached or when a theoretical maximum of $T$ charge units have been consumed. The second model is an extension of the first, allowing for more than one charge unit to be consumed in a time step, modeling
more bursty usage. Additionally, the battery has a non-zero probability of staying in the same charge state, indicating no consumption or recovery during a time step. Chiasserini and Rao extended their model further in following papers by adding state and phase dependence~\cite{chiasserini99,chiasserini01,chiasserini01b}. The state number is the number of charge units, and the phase number is the number of consumed charge units. Having fewer charge units decreases the probability of
recovery, while having more consumed charge units increases the probability of recover. Using these models, one can model different loads by setting the transition probabilities. However, the order of the transitions is uncontrollable, so it is impossible to model fixed load patterns and compute their impact on battery life.

Chiasserini and Rao mainly investigated the gain $G$ in transmitted packets using a pulsed discharge relative to using a constant discharge, defined as $G=m/N$, where $m$ is the mean number of transmitted packets. The gain increases when the load decreases, due to an increase in the recovery probability. Additionally, the gain increases for lower discharge demand rates and higher current densities. These load profiles result in discharge currents close to the specified limits of the battery, causing the
available capacity to decrease overly quickly. Therefore, the recovery effect is especially strong for these cases during pulsed discharge, greatly increasing the gain. Chiasserini and Rao compared the computation of the gain parameter for different current densities and demand rates using the stochastic model to that of the electrochemical model of Doyle et al. They found an average deviation of 1\% and a maximum deviation of 4\%. This shows that the stochastic model accurately describes battery behavior during pulsed discharge. However, this model is only able to compute relative lifetimes.

In 2005, Rao et al.~\cite{rao05} proposed a stochastic battery model for a nickel-metal hydride (NiMH) battery based on the Kinetic Battery Model (KiBaM) of Manwell and McGowan. The differential equations governing the original KiBaM were modified to include an extra factor $h_2$ governing the flow of charge between the wells. This changes \cref{eq:kibam} into
\begin{equation}
    \begin{cases}
        \dfrac{dy_1}{dt} = -I + k_s h_2 \left( h_2 - h_1 \right) \\
        \dfrac{dy_2}{dt} = -k_s h_2 \left( h_2 - h_1 \right),
    \end{cases}
\end{equation}
This change causes the recovery effect to weaken as the remaining charge decreases. The stochastic model was also modified to allow the possibility of no recovery during idle periods. The stochastic KiBaM describes the battery using a discrete-time, transient Markov process. The states are labeled with the parameters $(i,j,t)$, with $i$ and $j$ representing the discrete charge levels of the available and bound charge wells and $t$ representing the length of the current idle period.
Like the stochastic model of Chiasserini and Rao, it is impossible to fully model a real-life discharge pattern using the stochastic KiBaM. Rao et al.\ compared the results of their model with experimental results using an AAA NiMH battery. Two sets of experiments were conducted, the first with varying frequency of the load and a 50\% duty cycle and the second with varying off-time and a constant on-time. Their model accurately predicted the lifetime and delivered charge from the
battery, with a maximum error of 2.65\%.

\subsection{Electrical-Circuit}

Electrical-circuit models for batteries developed from the discovery of capacitative effects at the electrode-electrolyte interface. Helmholtz first proposed the existence of a double layer of charge at the interface in 1879. In 1899, Warburg proposed a series resistance and capacitance circuit model with an infinitely low current density. The Warburg capacitance $C_W$ named after him varies inversely with the square root of the frequency~\cite{geddes97}. In 1947, Randles proposed a model
consisting of a double-layer polarization capacitance $C_p$ in parallel with the series combination of a resistor $R$ and a capacitance $C$~\cite{randles47}. In 1994, Kovacs improved Randles circuit with the addition of Warburg impedance $Z_W$ replacing the capacitance $C$ and the solution resistance $R_s$ in series with the original Randles circuit~\cite{kovacs95}. In addition, he renamed $C_p$ to the double layer capacitance $C_{dl}$ and $R$ to the charge-transfer resistance
$R_{ct}$. These proposals came from a desire to represent impedance spectra created using electrochemical impedance spectroscopy (EIS). The various elements in the models represent the different processes within a battery, which have different time constants. While these attempts model the impedance and, thus, account for the nonlinear rate-capacity and recovery effects, they do not consider the capacity and self-discharge of the battery.

In 1993, Hageman created simplified electrical-circuit models using PSpice for nickel-cadmium (NiCd), lead-acid, and alkaline batteries~\cite{hageman93}. The circuits shared the common elements of
\begin{enumerate*}[label=\emph{\roman*})]
\item a capacitor that represents the battery capacity,
\item a discharge rate normalizer that determines the additional capacity loss at high discharge rates,
\item a circuit that discharges the battery,
\item a lookup table of battery voltage versus SOC, and
\item a resistor that represents the battery's internal resistance~\cite{hageman93,hageman97}.
\end{enumerate*}
In addition, battery models for NiCd batteries simulated the thermal effects under high discharge rates. The main lookup table is formed by discharging a battery at a low rate at a constant current (20 to 200 hours). At high discharge rates, the discharge rate normalizer reduces the battery voltage below the value from looking up the SOC in the table. This normalizer is implemented using additional lookup tables. These circuit models were much simpler than electrochemical models, but they
were also less accurate with an approximate error of 10\%. Furthermore, creation of the lookup tables requires considerable data. These circuit-based models were used to estimate the remaining discharge time and are referred to as runtime-based models.

In 2006, Chen and Rinc\'on-Mora proposed a combination of a runtime-based model and an impedance-based model consisting of a series resistor and two parallel resistor-capacitor networks~\cite{chen06}. A schematic for their model is shown in \cref{fig:batt_model}. The elements of the impedance part of the model had parameters that depended on the SOC. Additionally, the runtime model included a resistance that modeled the self-discharge rate. Their proposed model has the advantage of
accurate prediction of the SOC using the runtime-based portion while also modeling nonlinear transient effects, such as the rate-capacity and recover effects, with the impedance-based portion. Furthermore, the battery data can be collected using EIS measurements, which requires neither detailed knowledge of the battery chemistry nor lengthy, low-rate discharge experiments.

\subsection{Evaluation}

Of the model types, only some are fit for use with filtering algorithms. The computational-intelligence and stochastic models do not adequately describe the dynamics of the battery system for use in the filters covered by this study. On the other hand, electrochemical, analytical, and electrical-circuit models do describe the system dynamics in a compatible manner. Furthermore, they model the nonlinear rate-capacity and recovery effects. Of these, only the electrical-circuit model has the
advantage of modeling the internal impedance of the battery, which is useful in the design of battery systems. The relevant characteristics of the model types are summarized in \cref{tab:model_charac}. It can be seen that electrical-circuit models are the most suitable for this study. Among them, the proposal by Chen and Rinc\'on-Mora is most appropriate for the purposes of this thesis, because it is the only one discussed by this paper that describes both the capacity and the transient
effects. Therefore, their proposed model is used for simulating the battery and comparing the performance of different filters.

\begin{table}[htb]
\centering
\caption{Summary of relevant characteristics of various battery model types.}
\begin{tabular}{lccccc}
    \toprule
    Model Type & Dynamics & $\vcenter{\setbox0\hbox{\strut Nonlinear}\copy0\hbox to\wd0{\hss\strut Effects\hss}}$ & $\vcenter{\setbox0\hbox{\strut Transient}\copy0\hbox to\wd0{\hss\strut Effects\hss}}$ & $\vcenter{\setbox0\hbox{\strut Characteristics}\hbox to\wd0{\hss\strut I-V\hss}\copy0}$ & $\vcenter{\setbox0\hbox{\strut Difficulty}\hbox to\wd0{\hss\strut Design\hss}\copy0}$ \\
    \midrule
	Electrochemical & Y & Y & Y & N & High \\
    $\vcenter{\setbox0\hbox{\strut Computational\strut}\copy0\hbox to\wd0{\hspace{2ex}\strut Intelligence\hss}}$ & N & Y & Y & N & High \\
    Analytical & Y & Y & N & N & Low \\
    Stochastic & N & Y & N & N & Low \\
    Electrical-Circuit & Y & Y & Y & Y & Medium \\
    \bottomrule
\end{tabular}
\label{tab:model_charac}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Nonlinear Filtering Methods}

Filtering refers to the methodology for estimating the state of a time-varying system that is indirectly observed through noisy measurements. Specifically, the state at the current time is estimated using the measurements from the current and previous times. The state of a system is a group of dynamic variables that evolve through time, and its evolution through time is governed by a dynamic system, perturbed by process noise. The measurements are functions of the state and the
measurement noise.

Systems are classified as either linear or nonlinear. The state dynamics and measurements of a linear system are linear functions of the state, inputs, and noises. Particularly, the superposition principles of additivity and homogeneity are satisfied by a linear system. Nonlinear systems do not satisfy the principle of superposition because the functions defining the systems are not all linear, i.e.\ some are nonlinear. A battery can be modeled as a nonlinear, time-varying system,
with state variables that describe such states as the SOC and the SOH. The measurements are typically the voltage and the current. Note that the SOH was not considered by this thesis for reasons described in \cref{sec:echar}, so this thesis assumes the battery system is time-invariant. Additionally, only the voltage was measured since a known resistive load was used as an input to the system in place of the current measurement. This replacement was done because a piecewise constant discharge profile is convenient for simulation purposes and it is
more realistic to have a constant discharge load than a constant discharge current. A state-space representation of the battery system proposed by Chen and Rinc\'on-Mora in~\cite{chen06} is described in more detail in the following chapter.

%Note that this thesis uses a resistive load instead of the current, because this is more realistic from a usage standpoint. Additionally, the SOH is not considered by this thesis for reasons describe in \cref{sec:echar}. The dynamic system for the battery is described in more detail in the following chapter.

For linear systems, the optimal filtering solution with respect to the minimum mean squared error (MMSE) is given by the least squares solution, meaning the least squares solution equals the posterior mean. A closed form solution to the discrete-time linear filtering problem is given by the Kalman filter~\cite{kalman60}, which is a linear MMSSE (LMMSE) filter. Its solution procedure is as follows. Consider a linear system in discrete time with $n$ states and $m$ measurements defined by
\begin{align}
    \vx_k &= F_k \vx_{k-1} + B_k \vu_k + L \vw_k \\
    \vz_k &= H_k \vx_k + M \vv_k,
\end{align}
where $\vx\in\mathbb{R}^n$, $\vu\in\mathbb{R}^{N_u}$, and $\vz\in\mathbb{R}^m$ are vectors of the state variables, known inputs, and measurements, respectively; $\vw\sim\mathcal{N}(0,Q_k)$, $Q_k\in\mathbb{R}^{N_w\times N_w}$, and $\vv\sim\mathcal{N}(0,R_k)$, $R_k\in\mathbb{R}^{N_v\times N_v}$ are normally distributed noise variables; $F\in\mathbb{R}^{n\times n}$, $B\in\mathbb{R}^{n\times N_u}$, $H\in\mathbb{R}^{m\times n}$, $L\in\mathbb{R}^{n\times N_w}$, and $M\in\mathbb{R}^{m\times N_v}$ are matrices; and a subscript $k$ on a
variable indicates the value of that variable at time $t_k$, where $t_k=t_0+k\delta$ and $\delta$ is the time step. First, the Kalman filter propagates the estimates of the state variables $\hat{\vx}$ and the estimation covariances $P\in\mathbb{R}^{n\times n}$ according to
\begin{align}
    \hat{\vx}_{k|k-1} &= F_k \hat{\vx}_{k-1|k-1} + B_k \mathbf{u}_k \label{eq:kfp1} \\
    P_{k|k-1} &= F_k P_{k-1|k-1} F_k^\top + L Q_k L^\top, \label{eq:kfp2}
\end{align}
where $\hat{(\ )}$ indicates the estimated value. Then, the estimates are updated using the measurements according to
\begin{align}
    \tilde{\mathbf{z}}_k &= \mathbf{z}_k - H_k \hat{\vx}_{k|k-1} \label{eq:kfu1} \\
    S_k &= H_k P_{k|k-1} H_k^\top + M R_k M^\top \\
    K_k &= P_{k|k-1} H_k^\top S_k^{-1} \\
    \hat{\vx}_{k|k} &= \hat{\vx}_{k|k-1} + K_k \tilde{\mathbf{z}}_k \\
    P_{k|k} &= \left( I - K_k H_k \right) P_{k|k-1}. \label{eq:kful} 
\end{align}
The Kalman filter operates under the assumption that the process and measurement noises are Gaussian, so the posterior distribution is also Gaussian and numerical approximations of the posterior distribution are unnecessary. Under this assumption, the Kalman filter produces the optimal solution in the maximum likelihood (ML) and the maximum a posterior (MAP) senses, in addition to in the MMSE sense. However, the Gaussian assumption is unnecessary for the Kalman filter to produce the
optimal MMSE estimate for a general linear system.

For nonlinear systems, optimal filtering solutions are generally intractable, so various numerical approximation methods have been developed. Chen describes seven categories of such methods, namely Gaussian/Laplace approximation, iterative quadrature, multigrid method and point-mass approximation, moment approximation, Gaussian sum approximation, deterministic sampling approximation, and Monte Carlo sampling approximation~\cite{chen03}. Note that only filters using point-based
numerical approximation methods were studied, as opposed to those using density-based methods. This was done because typical battery management systems do not have the computational power to employ costly density-based methods, and point-based methods use the simple LMMSE update of the Kalman filter. Point-based and density-based methods are also known as local and global approaches, respectively. Additionally, only filters using methods from the two most popular categories of Gaussian
approximation and deterministic sampling approximation~\cite{li04} were used to further limit the scope of this study.

Gaussian approximation operates by assuming the posterior distribution is Gaussian. Then, the Taylor-series-based extended Kalman filter (EKF)~\cite{jazwinski70} or the Gaussian-describing-function-based statistically linearized filter (SLF)~\cite{gelb74} can be used. Li and Jilkov state that the EKF approximates the nonlinear dynamic and measurement functions, while the SLF simplifies the nonlinear stochastic system to a linear system so that linear filtering results are
applicable~\cite{li04}. Deterministic sampling methods are special numerical methods that estimate the mean and covariance. This category includes the unscented Kalman filter (UKF)~\cite{julier97} and the cubature Kalman filter (CKF)~\cite{arasaratnam10}. The main advantage of the deterministic sampling methods is they are derivative-free. The remainder of this section details the general implementation of these filters for a discrete-time system of the form
\begin{align}
    \vx_k &= \vf_d(\vx_{k-1},\vu_k) + L(\vx_{k-1},\vu_k) \vw_k \label{eq:dtsys_x} \\
    \mathbf{z}_k &= \vh(\vx_k,\vu_k) + M(\vx_k,\vu_k) \vv_k, \label{eq:dtsys_z}
\end{align}
where $\vf\in\mathbb{R}^n$ and $\vh\in\mathbb{R}^m$ are nonlinear vector functions, $L\in\mathbb{R}^{n\times N_w}$ and $M\in\mathbb{R}^{m\times N_v}$ are nonlinear matrix functions, and the input $\vu$ is assumed to be piecewise constant, meaning $\vu(t)=\vu(t_k)=\vu_k$ for $t_{k-1}<t\le t_k$. An implicit, first-order Taylor-Heun numerical integration method was used to discretize the continuous-time dynamics $\vf$ of the chosen battery model. In particular, an iterated integration
procedure was used, as was done by S\"arkk\"a~\cite{sarkka12}. For the iterations, a superscript of $(i)$ indicates the $i$th step of a $M$-step iterative integration scheme. Note that $\hat{\vx}^{(0)}_{k-1}=\hat{\vx}_{k-1}$ and $\hat{\vx}^{(M)}_{k-1}=\hat{\vx}_k$. The specifics of the discretization along with the notation used are discussed in \cref{sec:discret}.

\subsection{Extended Kalman Filter}
\label{sec:ekf}

One of the most popular nonlinear filters is the extended Kalman filter (EKF), which approximates the nonlinear state and measurement functions using Taylor series expansion. This study uses the first-order expansion for the EKF. The prediction step follows the discretization approach proposed by Mazzoni~\cite{mazzoni07} to numerically approximate the continuous-time dynamics in \cref{eq:ct_diff} and the continuous-time estimate covariance differential equation
\begin{equation}
    \dot{P} = F(\vx,\vu) P + P F^\top(\vx,\vu) + L(\vx,\vu) Q L^\top(\vx,\vu),
\end{equation}
with the Jacobian $F=\partial\vf/\partial\vx$. The discretization $\vf_d$ of $\vf$ is given in \cref{sec:discret}, and the discretion of the estimate covariance matrix is as follows. Note that an $M$-step iterative integration method was used for the discretization of $\vf$. Thus, a similar iterative procedure was used for the discretion of the estimate covariance matrix. For a time step of $\delta=(t_k-t_{k-1})/M$, where $M$ is a positive integer, the prediction step consists of $M$
iterations of the following equations:
\begin{align}
    \hat{\vx}_{k-1|k-1}^{(i)} &= \vf_d(\hat{\vx}_{k-1}^{(i-1)},\vu_k,\delta,i) \label{eq:ekfpredx} \\
    P_{k-1|k-1}^{(i)} &= \begin{multlined}[t] P_{k-1|k-1}^{(i-1)} + G_\tau \Big\{ F(\hat{\vx}_\tau,\vu_k) P_{k-1|k-1}^{(i-1)} + P_{k-1|k-1}^{(i-1)} F^\top(\hat{\vx}_\tau,\vu_k) \\ + L(\hat{\vx}_\tau,\vu_k) Q_\tau L^\top(\hat{\vx}_\tau,\vu_k) \Big\} G_\tau^\top \delta, \end{multlined} \label{eq:ekfpredz}
\end{align}
where $t_\tau = t_{k-1}+\delta(i+1/2)$, 
\begin{equation}
    G_\tau = \left( I - F(\hat{\vx}_\tau,\vu_k) \frac{\delta}{2} \right)^{-1},
\end{equation}
and
\begin{equation}
    \hat{\vx}_\tau = \frac{1}{2} \left( \hat{\vx}_{k-1}^{(i-1)} + \hat{\vx}_{k-1}^{(i)} - F(\hat{\vx}_{k-1}^{(i)},\vu_k) f(\hat{\vx}_{k-1}^{(i)}) \frac{\delta^2}{4} \right).
\end{equation}
The iteration given by \cref{eq:ekfpredx,eq:ekfpredz} is repeated $M$-times to complete the prediction step.  It can be seen that the differential equation for the covariance matrix was approximated using a modified Gauss-Legendre formula with an implicit increment rule, following Mazzoni. The numerical approximations for the state and covariance are both A-stable, which is necessary for the chosen battery model, and consistent to the first-order. 
The update equations for the EKF come from the LMMSE filter and are
\begin{align}
    K_k &= P_{k|k-1} H_k^\top \left( H_k P_{k|k-1} H_k^\top + M(\hat{\vx}_k) R_k M^\top(\hat{\vx}_k) \right)^{-1} \\
    \hat{\vx}_{k|k} &= \hat{\vx}_{k|k-1} + K_k \big( \mathbf{z}_k - \vh(\hat{\vx}_{k|k-1}) \big) \\
    P_{k|k} &= (I - K_k H_k) P_{k|k-1}, \label{eq:ekf_l}
\end{align}
with the Jacobian $H=\partial\vh/\partial\vx$.

\subsection{Unscented Kalman Filter}

The unscented Kalman filter (UKF) is an efficient, generally derivative-free filtering algorithm that relies on the unscented transformation (UT). The UT is useful for forming the Gaussian approximation to the joint distribution of random variables $x$ and $y$ for $x\sim \mathcal{N}(m,P)$ and $y=g(x)$, where $x\in\mathbb{R}^n$, $y\in\mathbb{R}^m$, and $g:\mathbb{R}^n\mapsto\mathbb{R}^m$ is a nonlinear function. Then, the first and second moments corresponding to the mean and covariance can be
easily found. Specifically, suppose the Gaussian approximation of the joint probability density of $x$ and $y$ has the form
\begin{equation}
    \begin{bmatrix} x \\ y \end{bmatrix} = \mathcal{N} \left( \begin{bmatrix} m \\ \mu_U \end{bmatrix}, \begin{bmatrix} P & C_U \\ C_U^\top & S_U \end{bmatrix} \right).
\end{equation}
Then, the UT picks $2n+1$ sample points $\{x_i\}$, commonly known as sigma points, along with the same number of weights $\{w_i\}$, as follows~\cite{sarkka07}. First, the sigma points are chosen from the columns of the matrix $\sqrt{(n+\lambda)P}$, giving
\begin{align}
    x^{(0)} & = m_x \label{eq:ut1} \\
    x^{(i)} & = m_x + \left[ \sqrt{(n+\lambda)P} \right]_i, \quad i=1,\dots,n \\
    x^{(i)} & = m_x - \left[ \sqrt{(n+\lambda)P} \right]_{i-n}, \quad i=n+1,\dots,2n
\end{align}
with the weights
\begin{align}
    W_0^{(m)} & = \frac{\lambda}{n+\lambda} \\
    W_0^{(c)} & = \frac{\lambda}{n+\lambda} + (1-\alpha^2+\beta) \\
    W_i^{(m)} & = W_i^{(c)} = \frac{1}{2(n+\lambda)}, \quad i=1,\dots,2n. \label{eq:ut2}
\end{align}
The parameter $\lambda$ is defined as
\begin{equation}
    \lambda = \alpha^2 (n+\kappa) - n,
\end{equation}
and the constants $\alpha$, $\beta$, and $\kappa$ are parameters of the method. For the UKF, $\alpha$ is a small positive number, e.g.\ $10^{-3}$, $\beta=2$ is ideal for a Gaussian distribution, and $\kappa$ is typically $0$. Each sigma point is transformed by
\begin{equation}
    y^{(i)} = g(x^{(i)}), \quad i=0,\dots,2n. \label{eq:ut3}
\end{equation}
Then, the moments are approximated by
\begin{align}
    \mu_U & = \sum_{i=0}^{2n} W_i^{(m)} y^{(i)} \\
    S_U & = \sum_{i=0}^{2n} W_i^{(c)} ( y^{(i)} - \mu_U ) ( y^{(i)} - \mu_U )^\top \\
    C_U & = \sum_{i=0}^{2n} W_i^{(c)} ( x^{(i)} - m ) ( y^{(i)} - \mu_U )^\top. \label{eq:ut4}
\end{align}
The square root of the positive definite matrix P is defined as a matrix $A$ such that $P=AA^\top$. Note that $A$ is not unique. For performance reasons, the Cholesky factorization is typically used.

Let the described UT algorithm be denoted by
\begin{equation}
    [\mu_U,S_U,C_U] = \mathrm{UT}(g,m,P).
\end{equation}
Then, for the discretized system in \cref{eq:dtsys_x,eq:dtsys_z}, for an $M$-step numerical integration scheme, the prediction step for the UKF can be written as
\begin{align}
    [\hat{\vx}_{k-1|k-1}^{(i)},\tilde{P}_{k-1|k-1}^{(i)}] & = \mathrm{UT}(\vf_d,\hat{\vx}_{k-1|k-1}^{(i-1)},P_{k-1|k-1}^{(i-1)}) \label{eq:ukfp1} \\
	P_{k-1|k-1}^{(i)} & = \tilde{P}_{k-1|k-1}^{(i)} + L(\hat{\vx}_{k-1|k-1}^{(i)}) Q_k L^\top(\hat{\vx}_{k-1|k-1}^{(i)}), \\
\end{align}
where the equations are performed for $i=1,\dots,M$. Then, the update step is given by
\begin{align}
	[\mu_k,\tilde{S}_k,C_k] & = \mathrm{UT}(\mathbf{h},\hat{\vx}_{k|k-1},P_{k|k-1}) \label{eq:ukfu1} \\
    S_k & = \tilde{S}_k + M(\hat{\vx}_{k|k-1}) R_k M^\top(\hat{\vx}_{k|k-1}) \\
    K_k & = C_k S_k^{-1} \\
    \hat{\vx}_{k|k} & = \hat{\vx}_{k|k-1}+ K_k (z_k-\mu_k) \\
	P_{k|k} & = P_{k|k-1}- K_k S_k K_k^\top. \label{eq:ukful}
\end{align}
Note that the mean and covariances were estimated using the UT, and the update is equivalent to the LMSSE update used in the Kalman filter.

For numerical stability reasons, this study employed a change to the above UKF procedure as suggested by Julier et al.~\cite{julier00}. In \cref{eq:ukfp1}, the covariance is estimated by
\begin{equation}
    \tilde{P}_{k|k-1} = \sum_{i=0}^{2n} W_i^{(c)} ( \hat{\vx}_{k|k-1}^{(i)} - \hat{\vx}_{k|k-1}^{(0)} ) ( \hat{\vx}_{k|k-1}^{(i)} - \hat{\vx}_{k|k-1}^{(0)} )^\top,
    \label{eq:ukf_c1}
\end{equation}
where the covariance is evaluated about the projected mean rather than the weighted mean. This change ensures the positive definiteness of the covariance matrix, as required by the definition of covariance. Another change, discovered by the author, that results in better numerical stability and lower MSE is the estimation of the cross-covariance in \cref{eq:ukfu1} by
\begin{equation}
    C_k = \sum_{i=0}^{2n} W_i^{(c)} ( \prescript{}{P_{k-1|k-1}}{\hat{\vx}}_{k|k-1}^{(i)} - \prescript{}{P_{k-1|k-1}}{\hat{\vx}}_{k|k-1}^{(0)} ) ( \prescript{}{P_{k|k-1}}{\hat{\vz}}_k^{(i)} - \mu_k )^\top,
    \label{eq:ukf_c2}
\end{equation}
where the prescripts indicate the estimate covariance matrix that was used to calculate the sigma points, so $\prescript{}{P_{k-1|k-1}}{\hat{\vx}}_{k|k-1}^{(i)}$ comes from the transformation of $\prescript{}{P_{k-1|k-1}}{\hat{\vx}}_{k-1|k-1}^{(i)}$ through $\vf_d$ and $\prescript{}{P_{k|k-1}}{\hat{\vz}}_k^{(i)}$ comes from the transformation of $\prescript{}{P_{k|k-1}}{\hat{\vx}}_{k|k-1}^{(i)}$ through $\vh$. Note that similar to \cref{eq:ukf_c1}, the cross-covariance is
evaluated about the projected mean $\hat{\vx}_{k|k-1}^{(0)}$ and the weighted mean $\mu_k$. The increase in stability and accuracy with the change in \cref{eq:ukf_c2} was discovered through experimentation. The reason for the improvement is unknown, but the change was used to produce the simulation results.

\subsection{Cubature Kalman Filter}

The cubature Kalman filter (CKF) is similar to the UKF except that it uses the spherical-radial cubature rule rather than the UT to approximate the Gaussian integrals. Indeed, the prediction and update steps of the CKF follow \crefrange{eq:ukfp1}{eq:ukful} except that the UT algorithms in \cref{eq:ukfp1,eq:ukfu1} are replaced by the corresponding cubature algorithm. This thesis explores the third-order and fifth-order CKFs, whose implementations are discussed in the following two sections.

\subsubsection{Third-Order CKF}
\label{sec:ckf3}

The third-order spherical-radial CKF of Arasaratnam et al.~\cite{arasaratnam09,arasaratnam10} is a special case of the UKF with $\alpha=1$, $\beta=0$, and $\kappa=0$. The third-order cubature rule chooses $2n$ cubature points, giving~\cite{arasaratnam10}
\begin{align}
    x^{(i)} & = m_x + \left[ \sqrt{nP} \right]_i, \quad i=1,\dots,n \label{eq:cr3_1} \\
    x^{(i)} & = m_x - \left[ \sqrt{nP} \right]_{i-n}, \quad i=n+1,\dots,2n,
\end{align}
where the matrix square root is computed using Cholesky factorization, as in the UT. Then, the moments are approximated by
\begin{align}
    \mu_U & = \frac{1}{2n} \sum_{i=1}^{2n} y^{(i)} \\
    S_U & = \frac{1}{2n} \sum_{i=1}^{2n} ( y^{(i)} - \mu_U ) ( y^{(i)} - \mu_U )^\top \\
    C_U & = \frac{1}{2n} \sum_{i=1}^{2n} ( x^{(i)} - m ) ( y^{(i)} - \mu_U )^\top. \label{eq:cr3_l}
\end{align}
The prediction and update steps follow \crefrange{eq:ukfp1}{eq:ukful} with the UTs in \cref{eq:ukfp1,eq:ukfu1} replaced by the third-order cubature rule given by \crefrange{eq:cr3_1}{eq:cr3_l}. The resulting third-order CKF is exact for polynomials of order three. Compared to the UKF, the third-order CKF is numerically more stable due to its positive weights. While the UKF has some desirable theoretical properties, its weights can be negative, causing numerical problems in some
cases~\cite{sarkka12}.

To increase numerical stability and accuracy, a change similar to that in \cref{eq:ukf_c2} was used, giving
\begin{equation}
    C_k = \frac{1}{2n} \sum_{i=0}^{2n} ( \prescript{}{P_{k-1|k-1}}{\hat{\vx}}_{k|k-1}^{(i)} - \hat{\vx}_{k|k-1} ) ( \prescript{}{P_{k|k-1}}{\hat{\vz}}_k^{(i)} - \mu_k )^\top.
    \label{eq:ckf3_c}
\end{equation}
This change was verified through experimentation to produce better results.

\subsubsection{Fifth-Order CKF}

The fifth-order spherical-radial CKF is a higher-order extension of the third-order CKF that is exact for polynomials of order five. Its cubature rule chooses $2n^2+1$ cubature points, giving~\cite{jia13,stroud71}
\begin{align}
    x^{(0)} & = m_x \\
    x^{(i)} & = m_x + \left[ \sqrt{n+2} e_i \right], & i&=1,\dots,n \label{eq:cr5_1} \\
    x^{(i)} & = m_x - \left[ \sqrt{n+2} e_{i-n} \right], & i&=n+1,\dots,2n \\
    x^{(i)} & = m_x + \left[ \sqrt{n+2} s^+_{i-2n} \right], & i&=2n+1,\dots,2n+\frac{n(n-1)}{2} \\
    x^{(i)} & = m_x - \left[ \sqrt{n+2} s^+_{i-2n-n(n-1)/2} \right], & i&=2n+\frac{n(n-1)}{2}+1,\dots,2n+n(n-1) \\
    x^{(i)} & = m_x + \left[ \sqrt{n+2} s^-_{i-2n-n(n-1)} \right], & i&=2n+n(n-1)+1,\dots,2n+\frac{3n(n-1)}{2} \\
    x^{(i)} & = m_x - \left[ \sqrt{n+2} s^-_{i-2n-3n(n-1)/2} \right], & i&=2n+\frac{3n(n-1)}{2}+1,\dots,2n^2,
\end{align}
where $e_i$ are the columns of the Cholesky factorization $\sqrt{P}$ and
\begin{equation}
    {s^{\pm}_i} = \left\{ \frac{1}{\sqrt{2}} (e_j \pm e_k) : j<k; j,k=1,2,\dots,n \right\}
\end{equation}
are scaled linear combinations of the columns $e_i$. The weights on the points are
\begin{align}
    W_0 & = \frac{2}{n+2} \\
    W_i & = \frac{4-n}{2(n+2)^2}, \quad i=1,\dots,2n \\
    W_i & = \frac{1}{(n+2)^2}, \quad i=2n+1,\dots,2n^2.
\end{align}
Then, moments are approximated by
\begin{align}
    \mu_U & = \sum_{i=0}^{2n^2} W_i y^{(i)} \\
    S_U & = \sum_{i=0}^{2n^2} W_i ( y^{(i)} - \mu_U ) ( y^{(i)} - \mu_U )^\top \\
    C_U & = \sum_{i=0}^{2n^2} W_i ( x^{(i)} - m ) ( y^{(i)} - \mu_U )^\top. \label{eq:cr5_l}
\end{align}
As in the third-order CKF, the prediction and update steps follow \crefrange{eq:ukfp1}{eq:ukful} with the UTs in \cref{eq:ukfp1,eq:ukfu1} replaced by the fifth-order cubature rule given by \crefrange{eq:cr5_1}{eq:cr5_l}. Note that unlike the third-order CKF and like the UKF, the weights of the fifth-order CKF can be negative.

As in the third-order CKF, to increase numerical stability and accuracy, a change similar to that in \cref{eq:ukf_c2} was used, giving
\begin{equation}
    C_k = \sum_{i=0}^{2n^2} W_i ( \prescript{}{P_{k-1|k-1}}{\hat{\vx}}_{k|k-1}^{(i)} - \hat{\vx}_{k|k-1} ) ( \prescript{}{P_{k|k-1}}{\hat{\vz}}_k^{(i)} - \mu_k )^\top.
    \label{eq:ckf5_c}
\end{equation}
This change was verified through experimentation to produce better results.

\subsection{Statistically Linearized Filter}

In the statistically linearized filter (SLF), the nonlinear state and measurement functions are statistically linearized to minimize the MSE. Then, the resulting linear system can be filtered using the linear Kalman filter. Specifically, given $\vx\sim\mathcal{N}(m,P)$, the nonlinear function $\vf(\vx)$ is linearized as~\cite{sarkka13,gelb74,li04}
\begin{equation}
    \vf(\vx) \approx \mathbf{b} + A (\vx - m),
\end{equation}
where the parameters $\mathbf{b}$ and $A$ are chosen to minimize the error
\begin{equation}
    \text{MSE}(\mathbf{b},A) = E \left[ \| \vf(\vx) - \mathbf{b} - A(\vx-m) \|^2 \right].
\end{equation}
Differentiating the MSE expression and setting the derivatives to zero, produces the optimal values
\begin{align}
    \mathbf{b} & = E[\vf(\vx)] \\
    A & = E[\vf(\vx) (\vx-m)^\top] P^{-1}.
\end{align}
These values reproduce the mean exactly but the covariance is an approximation. The expectations can be calculated analytically or numerically. Due to the difficulty of finding the analytical forms of the expectations, this study chooses to approximated them numerically using the third-order spherical-radial cubature rule described in~\cref{sec:ckf3}, which has the advantages of numerical stability and low computational complexity compared to the UT and fifth-order cubature rule,
respectively. The cubature approximation results in
\begin{align}
    \mathbf{b}_\vx & = E[\vf_d(\vx)] \approx \frac{1}{2n} \sum_{i=1}^{2n} \vf_d(\vx^{(i)}) \label{eq:slf1} \\
    A_\vx & = E[\vf(\vx)(\vx-m)^\top] E[(\vx-m)(\vx-m)^\top]^{-1} = E[F(\vx)] \approx \frac{1}{2n} \sum_{i=1}^{2n} F(\vx^{(i)})
    \intertext{for the expectations of the state mean and covariance and}
    \mathbf{b}_\mathbf{z} & = E[\mathbf{h}(\vx)] \approx \frac{1}{2n} \sum_{i=1}^{2n} \mathbf{h}(\vx^{(i)}) \\
    A_\mathbf{z} & = E[\mathbf{h}(\vx)(\vx-m)^\top] E[(\vx-m)(\vx-m)^\top]^{-1} = E[H(\vx)] \approx \frac{1}{2n} \sum_{i=1}^{2n} H(\vx^{(i)})
\end{align}
for the expectations of the measurement state and covariance, where the cubature points come from the columns of $\sqrt{nP}$. With the given statistically optimal linearization, the resulting linear system can be filtered using a procedure similar to the linear Kalman filter. The prediction phase, for an $M$-step numerical integration scheme, consists of peforming the following equations $M$ times for $i=1,\dots,M$ using the notation from \cref{sec:discret}:
\begin{align}
    \hat{\vx}_{k-1|k-1}^{(i)} &= \mathbf{b}_{\hat{\vx}_{k-1|k-1}^{(i-1)}} \\
    P_{k-1|k-1}^{(i)} &= A_{\hat{\vx}_{k-1|k-1}^{(i-1)}} P_{k-1|k-1}^{(i-1)} A_{\hat{\vx}_{k-1|k-1}^{(i-1)}}^\top + L({\hat{\vx}_{k-1|k-1}^{(i-1)}},\vu) Q_k L^\top({\hat{\vx}_{k-1|k-1}^{(i-1)}},\vu),
\end{align}
where the above equations are iterated over $i=1,\dots,M$. Note that the form is very similar to the Kalman filter prediction steps given by \cref{eq:kfp1,eq:kfp2}, where $E[\vx-m]=0$ has been used to simplify the calculation for $\hat{\vx}_{k|k-1}$. The update phase consists of
\begin{align}
    S_k &= A_\vz P_{k|k-1} A_\vz^\top + M(\vx,\vu) R_k M^\top(\vx,\vu) \\
    K_k &= P_{k|k-1} A_\vz^\top S_k^{-1} \\
    \hat{\vx}_{k|k} &= \hat{\vx}_{k|k-1} + K_k (\vz_k - \mathbf{b}_\vz) \\
    P_{k|k} &= \left( I - K_k A_\vz \right) P_{k|k-1}. \label{eq:slfl}
\end{align}
Again, this is very similar to the Kalman filter update steps given by \crefrange{eq:kfu1}{eq:kful}. The SLF is similar to the EKF in the sense that its equations have a similar form to the Kalman filter equations. In fact, ignoring the numerical approximation of the expectations, the SLF uses first-order Fourier-Hermite series expansion to approximate the nonlinear functions whereas the EKF uses Taylor series expansion. Furthermore, the SLF implementation of this study uses the same
mean estimation method as the third-order CKF. The covariance estimation differs because the SLF uses information about the first derivatives of the state and measurement functions.

\end{document}
